{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Libraries which we will need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install python-dotenv langchain langchain_openai langchain_pinecone langchain_experimental langchainhub\n",
    "\n",
    "- Jupyter Notebook : typing-inspect==0.8.0 typing_extensions==4.5.0 pydantic\n",
    "\n",
    "- pip install sqlalchemy / pip install --upgrade sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "result = llm(\"What do you uderstand by machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that involves training computer systems to learn and make predictions or decisions based on data, without being explicitly programmed to do so. It is a process of creating algorithms and statistical models that enable the computer to improve its performance on a specific task by learning from data. The goal of machine learning is to allow computers to learn and adapt on their own, without human intervention, by identifying patterns and making decisions based on these patterns. It is used in various applications such as image and speech recognition, natural language processing, medical diagnosis, and predictive analytics.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that involves training computer systems to learn and make predictions or decisions based on data, without being explicitly programmed to do so. It is a process of creating algorithms and statistical models that enable the computer to improve its performance on a specific task by learning from data. The goal of machine learning is to allow computers to learn and adapt on their own, without human intervention, by identifying patterns and making decisions based on these patterns. It is used in various applications such as image and speech recognition, natural language processing, medical diagnosis, and predictive analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a Data Sciene expert.\"),\n",
    "    HumanMessage(content=\"Give me a road to study Data Science in one year.\")\n",
    "]\n",
    "\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studying Data Science in one year requires a structured and focused approach. Here is a road map to help you navigate your journey:\n",
      "\n",
      "1. Month 1-2: Foundations of Data Science\n",
      "   - Start by understanding the basics of statistics, probability, and linear algebra.\n",
      "   - Learn a programming language such as Python or R, which are commonly used in Data Science.\n",
      "   - Familiarize yourself with data manipulation libraries like Pandas or dplyr.\n",
      "\n",
      "2. Month 3-4: Exploratory Data Analysis and Data Visualization\n",
      "   - Dive into exploratory data analysis techniques to gain insights from data.\n",
      "   - Learn data visualization tools like Matplotlib, Seaborn, or ggplot2 to effectively communicate findings.\n",
      "\n",
      "3. Month 5-6: Machine Learning\n",
      "   - Study the fundamentals of machine learning algorithms, including regression, classification, and clustering.\n",
      "   - Implement these algorithms using libraries like scikit-learn or caret.\n",
      "   - Understand model evaluation techniques and cross-validation.\n",
      "\n",
      "4. Month 7-8: Big Data and Distributed Computing\n",
      "   - Learn about distributed computing frameworks like Apache Hadoop and Apache Spark.\n",
      "   - Explore how to handle large datasets using tools like Spark SQL or PySpark.\n",
      "\n",
      "5. Month 9-10: Deep Learning and Neural Networks\n",
      "   - Gain knowledge of deep learning concepts, including artificial neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\n",
      "   - Implement deep learning models using libraries like TensorFlow or PyTorch.\n",
      "\n",
      "6. Month 11-12: Capstone Project and Specializations\n",
      "   - Work on a real-world data science project to apply your knowledge and showcase your skills.\n",
      "   - Choose a specialization based on your interests, such as natural language processing, computer vision, or time series analysis.\n",
      "   - Explore advanced topics like reinforcement learning, Bayesian statistics, or ensemble methods.\n",
      "\n",
      "Throughout the year, it is crucial to practice by working on hands-on projects and participating in Kaggle competitions. Additionally, supplement your learning with online courses, books, and attending data science meetups or webinars. Remember, consistency and continuous learning are key to becoming a proficient Data Scientist.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt and Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "            Explain me the {concept} like I'm 5 year old.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['concept'], template=\"\\n            Explain me the {concept} like I'm 5 year old.\\n\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nProbability is like a game of chance. Let's say we have a bag with 10 marbles in it - 5 are red and 5 are blue. If you close your eyes and pick one marble out of the bag, what are the chances of getting a red marble? It's like a guessing game, you might get a red marble or you might get a blue marble. The chances of getting a red marble are 5 out of 10, which is the same as saying 5 in 10 or 1 in 2. So, the probability of getting a red marble is 1 in 2 or 50%. It's like flipping a coin and trying to guess if it will land on heads or tails - there's a 50% chance of getting it right. \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(concept=\"Probability\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\nProbability is like a game of chance. Let's say we have a bag with 10 marbles in it - 5 are red and 5 are blue. If you close your eyes and pick one marble out of the bag, what are the chances of getting a red marble? It's like a guessing game, you might get a red marble or you might get a blue marble. The chances of getting a red marble are 5 out of 10, which is the same as saying 5 in 10 or 1 in 2. So, the probability of getting a red marble is 1 in 2 or 50%. It's like flipping a coin and trying to guess if it will land on heads or tails - there's a 50% chance of getting it right. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNatural Language Processing, or NLP for short, is like a special brain for computers that helps them understand and use words and sentences just like we do. Just like you learn new words and how to use them when you are learning to read and write, NLP helps computers learn new words and how to use them too. This helps computers talk and understand us better, just like how we talk and understand each other.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(concept=\"Natural Language Processing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'\\nNatural Language Processing, or NLP for short, is like a special brain for computers that helps them understand and use words and sentences just like we do. Just like you learn new words and how to use them when you are learning to read and write, NLP helps computers learn new words and how to use them too. This helps computers talk and understand us better, just like how we talk and understand each other.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Autoencoders are like magic boxes that can learn how to compress and uncompress things. Just like how you put your toys into a box and then take them out later, autoencoders can take in lots of information and then give it back to you in a smaller and simpler form. This helps us save space and understand things better.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm , prompt=prompt)\n",
    "\n",
    "print(chain.run(\"Autoencoders\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"code\"],\n",
    "    template=\"Turn the concept into a Python {code}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['code'], template='Turn the concept into a Python {code}') llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001F5193E24D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001F5193F6450>, openai_api_key=SecretStr('**********'), openai_proxy='')\n"
     ]
    }
   ],
   "source": [
    "print(chain_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "A neural network is like a game where you try to find matches. You have a collection of cards with different pictures on them and you have to match them together. But instead of using your eyes, you use your brain to figure out which cards go together. The more you play, the better you get at finding the matches. And just like how you learn new things every day, the neural network learns from the matches it finds and gets better at finding them. \u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "# Define a class for a Neural Network\n",
      "class NeuralNetwork:\n",
      "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
      "        # Initialize the number of input, hidden, and output nodes\n",
      "        self.num_inputs = num_inputs\n",
      "        self.num_hidden = num_hidden\n",
      "        self.num_outputs = num_outputs\n",
      "\n",
      "        # Randomly initialize the weights between the input and hidden layers\n",
      "        self.weights_input_hidden = np.random.rand(self.num_inputs, self.num_hidden)\n",
      "\n",
      "        # Randomly initialize the weights between the hidden and output layers\n",
      "        self.weights_hidden_output = np.random.rand(self.num_hidden, self.num_outputs)\n",
      "\n",
      "        # Initialize the input, hidden, and output layers\n",
      "        self.input_layer = np.zeros(self.num_inputs)\n",
      "        self.hidden_layer = np.zeros(self.num_hidden)\n",
      "        self.output_layer = np.zeros(self.num_outputs)\n",
      "\n",
      "    # Define a method to train the neural network\n",
      "    def train(self, input_data, target_data, learning_rate):\n",
      "        # Feed forward through the neural network\n",
      "        self.feed_forward(input_data)\n",
      "\n",
      "        # Calculate the error between the output layer and the target data\n",
      "        output_error = target_data - self.output_layer\n",
      "\n",
      "        # Calculate the gradient for the weights between the hidden and output layers\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "# Define a class for a Neural Network\n",
      "class NeuralNetwork:\n",
      "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
      "        # Initialize the number of input, hidden, and output nodes\n",
      "        self.num_inputs = num_inputs\n",
      "        self.num_hidden = num_hidden\n",
      "        self.num_outputs = num_outputs\n",
      "\n",
      "        # Randomly initialize the weights between the input and hidden layers\n",
      "        self.weights_input_hidden = np.random.rand(self.num_inputs, self.num_hidden)\n",
      "\n",
      "        # Randomly initialize the weights between the hidden and output layers\n",
      "        self.weights_hidden_output = np.random.rand(self.num_hidden, self.num_outputs)\n",
      "\n",
      "        # Initialize the input, hidden, and output layers\n",
      "        self.input_layer = np.zeros(self.num_inputs)\n",
      "        self.hidden_layer = np.zeros(self.num_hidden)\n",
      "        self.output_layer = np.zeros(self.num_outputs)\n",
      "\n",
      "    # Define a method to train the neural network\n",
      "    def train(self, input_data, target_data, learning_rate):\n",
      "        # Feed forward through the neural network\n",
      "        self.feed_forward(input_data)\n",
      "\n",
      "        # Calculate the error between the output layer and the target data\n",
      "        output_error = target_data - self.output_layer\n",
      "\n",
      "        # Calculate the gradient for the weights between the hidden and output layers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "explanation = overall_chain.run(\"Neural Network\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings and VectorStores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=\"Expalin the {concept} in detail.\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAutoencoders are like magic boxes that can help us find out which toys we like the most! \n",
      "They take all of our toys and put them in the box, but they only let a few toys out at a time. Then, they ask us to pick our favorites from the toys that came out. This helps the magic box figure out which toys we like the most. Then, the magic box puts all of our favorite toys back in the box and mixes them up. When it lets the toys out again, it only chooses the ones we like the most. This is how autoencoders help us find out which toys we like the most, or in other words, which features are most important to us.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Autoencoders are a type of artificial neural network that is used for unsupervised learning. They are composed of two main parts - an encoder and a decoder. The encoder takes in an input and compresses it into a lower dimensional representation, also known as a code or latent space. This code contains the most important features of the input data. The decoder then takes this code and reconstructs the original input.\n",
      "\n",
      "To understand how autoencoders work, let's use the example of the magic box and toys. Imagine we have a box full of different types of toys. The box is like the encoder, and it takes in all the toys and compresses them into a smaller space, just like how the encoder compresses the input data. The box only lets a few toys out at a time, and these toys represent a smaller representation of all the toys inside the box. This is similar to how the encoder creates a lower dimensional code of the input data.\n",
      "\n",
      "Next, the magic box asks us to pick our favorite toys from the ones that came out. This is like the decoder reconstructing the input data from the code. Based on the toys we pick, the magic box can understand which features are most important to us. Similarly, the decoder can understand which features are\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Autoencoders are a type of artificial neural network that is used for unsupervised learning. They are composed of two main parts - an encoder and a decoder. The encoder takes in an input and compresses it into a lower dimensional representation, also known as a code or latent space. This code contains the most important features of the input data. The decoder then takes this code and reconstructs the original input.\n",
      "\n",
      "To understand how autoencoders work, let's use the example of the magic box and toys. Imagine we have a box full of different types of toys. The box is like the encoder, and it takes in all the toys and compresses them into a smaller space, just like how the encoder compresses the input data. The box only lets a few toys out at a time, and these toys represent a smaller representation of all the toys inside the box. This is similar to how the encoder creates a lower dimensional code of the input data.\n",
      "\n",
      "Next, the magic box asks us to pick our favorite toys from the ones that came out. This is like the decoder reconstructing the input data from the code. Based on the toys we pick, the magic box can understand which features are most important to us. Similarly, the decoder can understand which features are\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "explanation = overall_chain.run(\"Autoencoders\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
    "\u001b[36;1m\u001b[1;3mAutoencoders are like magic boxes that can help us find out which toys we like the most! \n",
    "They take all of our toys and put them in the box, but they only let a few toys out at a time. Then, they ask us to pick our favorites from the toys that came out. This helps the magic box figure out which toys we like the most. Then, the magic box puts all of our favorite toys back in the box and mixes them up. When it lets the toys out again, it only chooses the ones we like the most. This is how autoencoders help us find out which toys we like the most, or in other words, which features are most important to us.\u001b[0m\n",
    "\u001b[33;1m\u001b[1;3m\n",
    "\n",
    "Autoencoders are a type of artificial neural network that is used for unsupervised learning. They are composed of two main parts - an encoder and a decoder. The encoder takes in an input and compresses it into a lower dimensional representation, also known as a code or latent space. This code contains the most important features of the input data. The decoder then takes this code and reconstructs the original input.\n",
    "\n",
    "To understand how autoencoders work, let's use the example of the magic box and toys. Imagine we have a box full of different types of toys. The box is like the encoder, and it takes in all the toys and compresses them into a smaller space, just like how the encoder compresses the input data. The box only lets a few toys out at a time, and these toys represent a smaller representation of all the toys inside the box. This is similar to how the encoder creates a lower dimensional code of the input data.\n",
    "\n",
    "Next, the magic box asks us to pick our favorite toys from the ones that came out. This is like the decoder reconstructing the input data from the code. Based on the toys we pick, the magic box can understand which features are most important to us. Similarly, the decoder can understand which features are\u001b[0m\n",
    "\n",
    "\u001b[1m> Finished chain.\u001b[0m\n",
    "\n",
    "\n",
    "Autoencoders are a type of artificial neural network that is used for unsupervised learning. They are composed of two main parts - an encoder and a decoder. The encoder takes in an input and compresses it into a lower dimensional representation, also known as a code or latent space. This code contains the most important features of the input data. The decoder then takes this code and reconstructs the original input.\n",
    "\n",
    "To understand how autoencoders work, let's use the example of the magic box and toys. Imagine we have a box full of different types of toys. The box is like the encoder, and it takes in all the toys and compresses them into a smaller space, just like how the encoder compresses the input data. The box only lets a few toys out at a time, and these toys represent a smaller representation of all the toys inside the box. This is similar to how the encoder creates a lower dimensional code of the input data.\n",
    "\n",
    "Next, the magic box asks us to pick our favorite toys from the ones that came out. This is like the decoder reconstructing the input data from the code. Based on the toys we pick, the magic box can understand which features are most important to us. Similarly, the decoder can understand which features are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explanation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Autoencoders are a type of artificial neural network that is used for unsupervised learning. They'),\n",
       " Document(page_content='are composed of two main parts - an encoder and a decoder. The encoder takes in an input and'),\n",
       " Document(page_content='compresses it into a lower dimensional representation, also known as a code or latent space. This'),\n",
       " Document(page_content='code contains the most important features of the input data. The decoder then takes this code and'),\n",
       " Document(page_content='reconstructs the original input.'),\n",
       " Document(page_content=\"To understand how autoencoders work, let's use the example of the magic box and toys. Imagine we\"),\n",
       " Document(page_content='have a box full of different types of toys. The box is like the encoder, and it takes in all the'),\n",
       " Document(page_content='toys and compresses them into a smaller space, just like how the encoder compresses the input data.'),\n",
       " Document(page_content='The box only lets a few toys out at a time, and these toys represent a smaller representation of'),\n",
       " Document(page_content='all the toys inside the box. This is similar to how the encoder creates a lower dimensional code of'),\n",
       " Document(page_content='the input data.'),\n",
       " Document(page_content='Next, the magic box asks us to pick our favorite toys from the ones that came out. This is like the'),\n",
       " Document(page_content='decoder reconstructing the input data from the code. Based on the toys we pick, the magic box can'),\n",
       " Document(page_content='understand which features are most important to us. Similarly, the decoder can understand which'),\n",
       " Document(page_content='features are')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autoencoders are a type of artificial neural network that is used for unsupervised learning. They'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model = \"text-embedding-3-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012830266168338735,\n",
       " -0.017189465959762045,\n",
       " -0.005580392827377605,\n",
       " -0.04083013279974387,\n",
       " 0.0009030137122717436,\n",
       " 0.032256011851679714,\n",
       " 0.01312912386587649,\n",
       " 0.003426557040114433,\n",
       " -0.012335605344411957,\n",
       " 0.02333150498918084,\n",
       " -0.015633345101913082,\n",
       " -0.025598699966517275,\n",
       " -0.0461683472917897,\n",
       " 0.00829587528234327,\n",
       " 0.03646062792373473,\n",
       " 0.013541341219148805,\n",
       " 0.00980046885461787,\n",
       " -0.02300173110656299,\n",
       " 0.00140411550510298,\n",
       " -0.029288045045473846,\n",
       " 0.02607275062127239,\n",
       " -0.05037296708913512,\n",
       " -0.022156684368201493,\n",
       " -0.04925997697567076,\n",
       " 0.008316486382837536,\n",
       " 0.0022298384636361647,\n",
       " 0.002246584808164768,\n",
       " -0.016869996230407424,\n",
       " -0.05725699456047628,\n",
       " -0.0031148177540137384,\n",
       " 0.01627228083533192,\n",
       " -0.024011662923588212,\n",
       " -0.008254653081354736,\n",
       " -0.020847894853638516,\n",
       " -0.054866136705464655,\n",
       " 0.027123904639286142,\n",
       " -0.00421234651530894,\n",
       " 0.0004885420344347838,\n",
       " -0.03450259665984449,\n",
       " -0.011758501049830717,\n",
       " 0.04274694372529079,\n",
       " -0.03299800401889249,\n",
       " -0.01596311898453093,\n",
       " 0.03293617164873229,\n",
       " 0.0019709144822677386,\n",
       " -0.019631853894315838,\n",
       " -0.004758534624810083,\n",
       " -0.019054748668411996,\n",
       " 0.015035629706837573,\n",
       " -0.006136886487125881,\n",
       " -0.02225973893935022,\n",
       " -0.00460395323374829,\n",
       " -0.015942506952714066,\n",
       " 0.00881629928339593,\n",
       " -0.050908846388760025,\n",
       " 0.03167890848842108,\n",
       " 0.016158922110919956,\n",
       " -0.01703488317171635,\n",
       " 0.01806542702055844,\n",
       " 0.02357883446982163,\n",
       " -0.009733483476503456,\n",
       " 0.04066524772108015,\n",
       " -0.009120309988887899,\n",
       " 0.006404827533922235,\n",
       " 0.00037453813629061995,\n",
       " -0.03268883844280109,\n",
       " 0.054824912641830925,\n",
       " 0.002368961762157908,\n",
       " 0.04493169616329536,\n",
       " 0.025021596603258634,\n",
       " -0.030668974808750655,\n",
       " -0.005590698377624738,\n",
       " -0.011202007855743741,\n",
       " 0.04818821465113055,\n",
       " 0.0072086516056339,\n",
       " 0.017096715541876546,\n",
       " -0.034337707855890354,\n",
       " 0.0568860003395151,\n",
       " 0.008594732979881023,\n",
       " 0.01628258685124035,\n",
       " 0.016375335406480646,\n",
       " -0.01710702155778498,\n",
       " 0.04056219128728622,\n",
       " 0.007991864576851299,\n",
       " 0.036563684357528665,\n",
       " -0.0015574088770068692,\n",
       " 0.021414694063633926,\n",
       " -0.03073080717891085,\n",
       " 0.03728506449292456,\n",
       " 0.010527001997967987,\n",
       " -0.0493012010393045,\n",
       " 0.023702501072787225,\n",
       " -0.006404827533922235,\n",
       " 0.02362005667081016,\n",
       " -0.002785043871395886,\n",
       " 0.026093360790444053,\n",
       " 0.005771043411473713,\n",
       " -0.0028468764743867334,\n",
       " -0.018807419187771207,\n",
       " 0.02172385591443491,\n",
       " -0.010423947426819258,\n",
       " 0.0029911525480320438,\n",
       " -0.012077969847862736,\n",
       " 0.010140547821821555,\n",
       " -0.006770670609574403,\n",
       " -0.028504832539917747,\n",
       " 0.007940337291276934,\n",
       " 0.0016578868277631646,\n",
       " 0.009805620931249485,\n",
       " 0.024774265259972644,\n",
       " 0.006564561932938245,\n",
       " -0.008316486382837536,\n",
       " 0.013283705722599582,\n",
       " 0.021270417291496663,\n",
       " 0.017395573239414302,\n",
       " 0.017333740869254103,\n",
       " -0.04344771182886982,\n",
       " -0.046951559797345804,\n",
       " 0.018374590734004628,\n",
       " -0.0004585918637231132,\n",
       " 0.0017931457195652213,\n",
       " 0.000984813115139592,\n",
       " -0.01949788313808701,\n",
       " -0.0007355504416086968,\n",
       " -0.03681101383816945,\n",
       " -0.00016842944510254675,\n",
       " -0.00292416716991763,\n",
       " 0.017797485508100785,\n",
       " 0.006002915730897053,\n",
       " 1.3707033245191e-05,\n",
       " -0.009331571207816974,\n",
       " 0.008867826568970293,\n",
       " -0.0014942880220274676,\n",
       " 0.026959017697977216,\n",
       " 0.005899861625409624,\n",
       " 0.018436423104164823,\n",
       " 0.029391099616622573,\n",
       " 0.027659787664201452,\n",
       " 0.039696534379753054,\n",
       " -0.03827438614077812,\n",
       " -0.023475779898672902,\n",
       " 0.01241804881506642,\n",
       " -0.03555375067785824,\n",
       " -0.05593789903000487,\n",
       " 0.03437893191952409,\n",
       " 0.012613851941455445,\n",
       " 0.024526935779331856,\n",
       " 0.07048917765411451,\n",
       " 0.006569714940892462,\n",
       " -0.017230686298105376,\n",
       " 0.012253161873757495,\n",
       " 0.017735653137940587,\n",
       " -0.006461507827450816,\n",
       " -0.01620014431190849,\n",
       " 0.00620902440753321,\n",
       " -0.005559782192544639,\n",
       " 0.007414760282270057,\n",
       " 0.0039186418257254035,\n",
       " -0.008476220316192244,\n",
       " -0.021187974752164804,\n",
       " 0.008939964955038925,\n",
       " -0.023310892957363976,\n",
       " 0.02143530423280559,\n",
       " 0.026814740925839953,\n",
       " -0.009687109198883308,\n",
       " -0.007399302189730008,\n",
       " 0.0333483862080368,\n",
       " 0.004392691549157915,\n",
       " -0.03285372724675523,\n",
       " 0.03866599239355617,\n",
       " 0.0136650068907918,\n",
       " 0.014406998126681968,\n",
       " 0.048270655327817207,\n",
       " -0.008429846038572096,\n",
       " 0.006543951298105279,\n",
       " -0.00348838964310528,\n",
       " 0.012953931839981732,\n",
       " -0.008321638459469151,\n",
       " -0.013067291495716293,\n",
       " -0.0023547919216064133,\n",
       " -0.0062502461428604415,\n",
       " 0.03623391047491081,\n",
       " 0.04066524772108015,\n",
       " 0.013922642387341021,\n",
       " 0.02757734326222439,\n",
       " 0.04781721670487896,\n",
       " 0.009743788561089288,\n",
       " 0.012222245688677396,\n",
       " 0.045632464266874395,\n",
       " -0.03788277988800007,\n",
       " 0.01330431682309385,\n",
       " -0.010831011772137357,\n",
       " 0.03223539981986285,\n",
       " 0.011706973764256352,\n",
       " 0.005425811436315812,\n",
       " -0.0032745519201990976,\n",
       " -0.021373471862645394,\n",
       " 0.011624530293601889,\n",
       " -0.004142784633217418,\n",
       " 0.010583681360173968,\n",
       " 0.02947354401859964,\n",
       " -0.0394285928672954,\n",
       " 0.020847894853638516,\n",
       " 0.022239128770178557,\n",
       " -0.01155239283885586,\n",
       " 0.02221851673836169,\n",
       " 0.014180278815212844,\n",
       " 0.02833994559860882,\n",
       " -0.01752954399564313,\n",
       " -0.009218211552082411,\n",
       " -0.004390115045180807,\n",
       " -0.04219044866855861,\n",
       " -0.036934678578489845,\n",
       " -0.00842469303061788,\n",
       " 0.048641653274068795,\n",
       " -0.01810664922154697,\n",
       " -0.016189838296000056,\n",
       " 0.00864110725750117,\n",
       " 0.003511577014746004,\n",
       " 0.038006444628320465,\n",
       " -0.008316486382837536,\n",
       " -0.0008933524044342128,\n",
       " 0.029576598589748367,\n",
       " 0.009099698888393633,\n",
       " 0.009094545880439417,\n",
       " -0.06137916995584464,\n",
       " 0.02006468234808242,\n",
       " -0.03163768442478734,\n",
       " -0.01596311898453093,\n",
       " -0.008733855812741467,\n",
       " -0.020239873442654575,\n",
       " 0.05602034343198194,\n",
       " 0.038954542212540286,\n",
       " -0.01330431682309385,\n",
       " -0.023022341275734656,\n",
       " -0.06076084252895226,\n",
       " 0.012995153109647661,\n",
       " -0.00522485530197257,\n",
       " -0.013984474757501218,\n",
       " -0.016354725237308982,\n",
       " -0.026443746704878774,\n",
       " 0.03584230422213276,\n",
       " -0.06595478397415123,\n",
       " -0.048023325847176425,\n",
       " 0.034914814944439404,\n",
       " -0.013891726202260923,\n",
       " 0.02440326917636626,\n",
       " -0.035801080158499025,\n",
       " 0.0024436761865423468,\n",
       " 0.0051630229318123735,\n",
       " 0.025392590824219817,\n",
       " 0.005461880629350127,\n",
       " -0.0012186176961304382,\n",
       " -0.008548357770938273,\n",
       " -0.05276382494414675,\n",
       " -0.005211973713409629,\n",
       " 0.018838335372851307,\n",
       " -0.012572630671789514,\n",
       " 0.0051630229318123735,\n",
       " -0.0006975491034222006,\n",
       " -0.0032127193172082503,\n",
       " -0.0034703552794187725,\n",
       " -0.0546600275631672,\n",
       " 0.050785181648439634,\n",
       " -0.026855963126828485,\n",
       " -0.046498121174407554,\n",
       " 0.010573376275588136,\n",
       " -0.04583857340917185,\n",
       " 0.02417654986489714,\n",
       " -0.0002510339618074947,\n",
       " 0.04270572338694746,\n",
       " 0.0017995865138466917,\n",
       " -0.010063257359121308,\n",
       " -0.02318722821704358,\n",
       " 0.0035605277963432604,\n",
       " -0.016653582934846735,\n",
       " -0.009043019526187654,\n",
       " -0.0106249035611625,\n",
       " 0.01280965506784447,\n",
       " 0.024815487460961176,\n",
       " -0.023063563476723187,\n",
       " -0.051485953477309075,\n",
       " 0.0031972612246682014,\n",
       " -0.0022517375832883345,\n",
       " -0.061544058759798764,\n",
       " -0.04546757918821067,\n",
       " -0.06752120898526344,\n",
       " -0.01560242798551038,\n",
       " -0.036687349097849056,\n",
       " -0.02081697866855842,\n",
       " -0.0011612937422688803,\n",
       " 0.015138683346663701,\n",
       " -0.02207424182886963,\n",
       " -0.007517814853418786,\n",
       " -0.002330316530807785,\n",
       " -0.003171497581881019,\n",
       " -0.009918981518306648,\n",
       " -0.039820199120073445,\n",
       " 0.024382659007194597,\n",
       " -0.005121801196485142,\n",
       " 0.005585545835331822,\n",
       " -0.015386014689949691,\n",
       " 0.023702501072787225,\n",
       " 0.0009043019060526353,\n",
       " -0.008476220316192244,\n",
       " 0.010238449385016066,\n",
       " 0.007038612122032058,\n",
       " 0.009197600451588146,\n",
       " 0.005709211041313516,\n",
       " -0.023949830553428014,\n",
       " 0.016323809052228883,\n",
       " 0.021332249661656862,\n",
       " -0.0035064242396224375,\n",
       " -0.04501414056527243,\n",
       " -0.02908193776582159,\n",
       " -0.014674939639139623,\n",
       " 0.01605586753977123,\n",
       " 0.002321299232549206,\n",
       " -0.0003207566716707672,\n",
       " 0.037697279052229075,\n",
       " 0.008739008820695683,\n",
       " 0.011820333419990914,\n",
       " -0.01829214633202756,\n",
       " 0.019075360700228864,\n",
       " -0.003758907426709393,\n",
       " 0.015695177472073277,\n",
       " 0.023249060587203777,\n",
       " 0.01910627688530896,\n",
       " 0.013190956236036687,\n",
       " 0.004351469813830684,\n",
       " -0.002759280228608704,\n",
       " 0.0026691077116842163,\n",
       " 0.039325540158791875,\n",
       " 0.0013126547361899381,\n",
       " 0.006729448874247171,\n",
       " -0.0025377132266018467,\n",
       " -0.007059222756865023,\n",
       " 0.0017519239842379898,\n",
       " -0.016890608262224292,\n",
       " -0.02601091825111219,\n",
       " -0.014510052697830697,\n",
       " 0.00445710042329522,\n",
       " -0.04765233162621524,\n",
       " -0.015118073177492036,\n",
       " 0.01741618527123117,\n",
       " -0.0012707889912837546,\n",
       " -0.0461683472917897,\n",
       " 0.005838028789588127,\n",
       " -0.0016746331722917681,\n",
       " -0.01262415795736388,\n",
       " 0.0001611029339231984,\n",
       " -0.03660490469587199,\n",
       " -0.01916810925546916,\n",
       " 0.014551273967496628,\n",
       " -0.0013835046374393641,\n",
       " -0.010078715451661358,\n",
       " -0.01914749722365229,\n",
       " 0.05062029656977591,\n",
       " -0.0044416423307551715,\n",
       " 0.02702085006813741,\n",
       " -0.03411099040706644,\n",
       " 0.02908193776582159,\n",
       " -0.003882572632691088,\n",
       " -0.017045189187624783,\n",
       " 0.009156379181922214,\n",
       " 0.00024040647953046392,\n",
       " -0.010717652116402795,\n",
       " -0.009924133594938263,\n",
       " 0.021167362720347936,\n",
       " 0.0028649108380732406,\n",
       " -0.02135286169347373,\n",
       " 0.018663142415633948,\n",
       " 0.005714363583606432,\n",
       " 0.008749313905281515,\n",
       " 0.016478389977629376,\n",
       " -0.027350623950755264,\n",
       " 0.019405134582846716,\n",
       " -0.006590325575725427,\n",
       " -0.0028365709241396004,\n",
       " 0.009723177460595022,\n",
       " -0.008125835333080126,\n",
       " 0.019075360700228864,\n",
       " -0.05416536487659522,\n",
       " 0.026134582991432585,\n",
       " 0.02178569014724031,\n",
       " 0.0003260703909814091,\n",
       " -0.032070514741199124,\n",
       " -0.0008392488477133902,\n",
       " 0.01835397870218776,\n",
       " 0.0022968238417505784,\n",
       " 0.017766569323020686,\n",
       " -0.053299707969062055,\n",
       " 0.0017029730862254085,\n",
       " -0.03192623796906186,\n",
       " 0.031122413431688898,\n",
       " 0.015035629706837573,\n",
       " -0.006147192037373014,\n",
       " 0.01735435290107097,\n",
       " -0.019807044988887995,\n",
       " -0.013448592663908509,\n",
       " -0.04497291650163869,\n",
       " 0.02300173110656299,\n",
       " -0.013221873352439387,\n",
       " -0.014097835344558381,\n",
       " -0.049960748804540205,\n",
       " 0.0009719313519536636,\n",
       " -0.04748744282226111,\n",
       " -0.022383403679670615,\n",
       " 0.04130418345449899,\n",
       " 0.0016669041260217435,\n",
       " 0.011531781738361594,\n",
       " -0.010058104351167092,\n",
       " -0.01782840169318088,\n",
       " -0.013726839260951997,\n",
       " 0.025598699966517275,\n",
       " 0.014716160908805554,\n",
       " -0.023352115158352508,\n",
       " 0.014942880220274676,\n",
       " 0.020415066399871937,\n",
       " 0.005374284150741447,\n",
       " 0.015066545891917672,\n",
       " 0.04324160641186277,\n",
       " 0.012026442562288372,\n",
       " -0.019363912381858184,\n",
       " 0.010094173544201406,\n",
       " -0.009748941569043506,\n",
       " -0.014376081941601868,\n",
       " 0.007940337291276934,\n",
       " 0.017199770113025276,\n",
       " -0.018735280801702576,\n",
       " 0.029617818928091698,\n",
       " 0.01241804881506642,\n",
       " 0.027206347178618005,\n",
       " 0.036872846208329646,\n",
       " -0.011263840225903939,\n",
       " -0.024011662923588212,\n",
       " 0.011315367511478302,\n",
       " -0.011603919193107623,\n",
       " -0.02164141337510305,\n",
       " -0.007481745660384471,\n",
       " -0.025701754537666002,\n",
       " 0.034667481738508206,\n",
       " -0.006420286092123585,\n",
       " -0.00344459163663159,\n",
       " -0.03652246029389493,\n",
       " 0.0038593852610503635,\n",
       " 0.017292520530910776,\n",
       " -0.04658056557638462,\n",
       " 0.018498255474325022,\n",
       " -0.02382616581310762,\n",
       " -0.03260639404082403,\n",
       " 0.009202753459542362,\n",
       " -0.04254083458299333,\n",
       " -0.05635011731459979,\n",
       " 0.03722323212276437,\n",
       " -0.009501611157080116,\n",
       " 0.02568114436849434,\n",
       " 0.026134582991432585,\n",
       " 0.014922270051103012,\n",
       " 0.003807858208306649,\n",
       " 0.012387132629986322,\n",
       " 0.026464356874050438,\n",
       " 0.022115464029858162,\n",
       " -0.026340692133730043,\n",
       " 0.02006468234808242,\n",
       " 0.0204047603839635,\n",
       " -0.006997390386704826,\n",
       " -0.010042646258627042,\n",
       " -0.010253907477556116,\n",
       " -0.013438286648000076,\n",
       " 0.005230008309926787,\n",
       " -0.02512464931176216,\n",
       " 0.050166857946837666,\n",
       " 0.0409331855082474,\n",
       " -0.0013500119483821572,\n",
       " 0.046127126953446375,\n",
       " -0.04620957135542344,\n",
       " -0.05367070591531364,\n",
       " -0.0026768367579542407,\n",
       " 0.004583342133254024,\n",
       " -0.007332316811615594,\n",
       " -0.029205602506141983,\n",
       " 0.027536121061235857,\n",
       " 0.0006263771973832985,\n",
       " -0.028216280858288426,\n",
       " -0.011727584864750618,\n",
       " 0.017941762280238045,\n",
       " 0.03790338819452653,\n",
       " -0.018271536162855897,\n",
       " -0.016519612178617908,\n",
       " 0.027968949515002436,\n",
       " -0.00577619641942793,\n",
       " -0.02232157130951042,\n",
       " -0.02172385591443491,\n",
       " -0.009027560502325003,\n",
       " -0.038006444628320465,\n",
       " 0.0026150041549633934,\n",
       " -0.004163395733711684,\n",
       " 0.023558224300649966,\n",
       " 0.04501414056527243,\n",
       " 0.006100817294091565,\n",
       " -0.02586664147897493,\n",
       " -0.012067663831954302,\n",
       " 0.0060699011090114665,\n",
       " 0.005271230045254018,\n",
       " -0.003277128191345556,\n",
       " 0.013644395790297534,\n",
       " 0.014881047850114478,\n",
       " -0.01867344843154238,\n",
       " -0.010078715451661358,\n",
       " -0.004421031695922206,\n",
       " -0.0280513939169795,\n",
       " 0.01633411506813732,\n",
       " 0.024444491377354792,\n",
       " 0.007739381622594993,\n",
       " 0.030751417348082514,\n",
       " 0.029823928070389156,\n",
       " -0.00269229485049429,\n",
       " -0.005827723239340994,\n",
       " 0.025330758454059618,\n",
       " 0.011150480570169376,\n",
       " -0.0051733284820595065,\n",
       " 0.013984474757501218,\n",
       " -0.002831418149016034,\n",
       " -0.019126887054480627,\n",
       " 0.021888742855743836,\n",
       " 0.013716534176366164,\n",
       " 0.011583309023935957,\n",
       " -0.004263873800883305,\n",
       " -0.04484925176131829,\n",
       " -0.007450829475304373,\n",
       " 0.017735653137940587,\n",
       " -0.04303549726956531,\n",
       " -0.02572236470683767,\n",
       " -0.01627228083533192,\n",
       " 0.014262722285867308,\n",
       " 0.0213116394924852,\n",
       " 0.024341436806206065,\n",
       " -0.03839805088109852,\n",
       " -0.019518493307258675,\n",
       " -0.011191701839835307,\n",
       " 0.017426489424494398,\n",
       " -0.004665785603908487,\n",
       " 0.018467339289244922,\n",
       " -0.012119191117528667,\n",
       " -0.031081191230700366,\n",
       " 0.02475365509080098,\n",
       " -0.01913719307038906,\n",
       " 0.003555375021219694,\n",
       " -0.002457846259924492,\n",
       " 0.008867826568970293,\n",
       " 0.021806300316411974,\n",
       " -0.020198653104311248,\n",
       " 0.008744161828649899,\n",
       " -0.004245839204366147,\n",
       " 0.007074680849405072,\n",
       " -0.03122546800283763,\n",
       " 0.009537680350114432,\n",
       " 0.02314600601605505,\n",
       " -0.009656192082480608,\n",
       " 0.01159361410852179,\n",
       " 0.007466287567844422,\n",
       " 0.010614597545254066,\n",
       " 0.010738263216897062,\n",
       " -0.002273636470109854,\n",
       " -0.018147871422535503,\n",
       " 0.021620803205931384,\n",
       " 0.010367267133290677,\n",
       " -0.005729821676146481,\n",
       " 0.015478763245189986,\n",
       " -0.0051810575283295305,\n",
       " 0.009558290519286096,\n",
       " 0.004289637443670486,\n",
       " -0.004954337751199107,\n",
       " 0.025639922167505807,\n",
       " 0.005884403532869575,\n",
       " 0.021146752551176273,\n",
       " 0.006765518067281486,\n",
       " 0.003359571662000019,\n",
       " 0.009522222257574382,\n",
       " 0.004227804607848989,\n",
       " -0.02908193776582159,\n",
       " -0.010717652116402795,\n",
       " 0.021558968973125984,\n",
       " 0.021868132686572173,\n",
       " 0.0017622294180697977,\n",
       " -0.004323130132727694,\n",
       " 0.0003168921194319236,\n",
       " -0.020363540045620174,\n",
       " 0.004853859684027487,\n",
       " -0.029844540102206024,\n",
       " 0.015282960118800962,\n",
       " 0.0001400090008677061,\n",
       " -0.01803451083547834,\n",
       " -0.014922270051103012,\n",
       " 0.010707347031816963,\n",
       " 0.00016907354199299259,\n",
       " -0.0011284450627906254,\n",
       " 0.01256232465588108,\n",
       " 0.005134682785048083,\n",
       " 0.011830639435899347,\n",
       " 0.0024745926044530955,\n",
       " 0.012067663831954302,\n",
       " 0.004949185208906191,\n",
       " 0.003637818491874157,\n",
       " -0.004366927906370733,\n",
       " 0.033018612325418945,\n",
       " 0.0012321435271029813,\n",
       " 0.00266395493656065,\n",
       " -0.019868879221693395,\n",
       " -0.003380182529663635,\n",
       " -0.005874097982622442,\n",
       " 0.033101056727396015,\n",
       " -0.007646632601693397,\n",
       " -0.017653210598608724,\n",
       " 0.009687109198883308,\n",
       " 0.0012572630438958865,\n",
       " 0.0005890199851910793,\n",
       " -0.014757383109794086,\n",
       " 0.016004341185519466,\n",
       " -0.0079609483917712,\n",
       " -0.010372420141244895,\n",
       " 0.017488323657299798,\n",
       " 0.005626767570659053,\n",
       " -0.005910166709995457,\n",
       " 0.019580325677418874,\n",
       " 0.041345403792842315,\n",
       " -0.03382243686279191,\n",
       " -0.0021821759340274628,\n",
       " 0.020353234029711738,\n",
       " 0.0039933557844485405,\n",
       " -0.003939252460558368,\n",
       " -0.009718025383963406,\n",
       " 0.0021937695034324996,\n",
       " 0.0007703312662391328,\n",
       " 0.00393667595658126,\n",
       " -0.009774704746169387,\n",
       " 0.014963491320768942,\n",
       " 0.04592101781114891,\n",
       " -0.005564934734837555,\n",
       " -0.01925055179480102,\n",
       " 0.015684871456164845,\n",
       " 0.005992610180649919,\n",
       " 0.004235533654119014,\n",
       " -0.01606617355567966,\n",
       " 0.0008914201428667067,\n",
       " -0.05445391842086974,\n",
       " -0.04361260063282395,\n",
       " 0.01560242798551038,\n",
       " 0.009135768081427948,\n",
       " -0.024526935779331856,\n",
       " 0.015406624859121356,\n",
       " 0.008718397720201417,\n",
       " 0.007394149647437092,\n",
       " -0.01961124186249897,\n",
       " -0.012273772974251761,\n",
       " 0.04361260063282395,\n",
       " 0.02475365509080098,\n",
       " -0.020549037156100763,\n",
       " -0.002805654739059502,\n",
       " -0.020703618081501257,\n",
       " 0.0060699011090114665,\n",
       " -0.03672856943619238,\n",
       " -0.03143157528248988,\n",
       " 0.015695177472073277,\n",
       " -0.005673141848279201,\n",
       " 0.01935360636594975,\n",
       " -0.0006289535849450818,\n",
       " -0.01402569695848975,\n",
       " 0.005724669133853565,\n",
       " 0.0027901964136888024,\n",
       " -0.04060341162562955,\n",
       " -0.0018974881934565291,\n",
       " 0.026567411445199165,\n",
       " 0.021414694063633926,\n",
       " -0.007543578496205969,\n",
       " 0.021476526433794125,\n",
       " -0.004408149641697965,\n",
       " 0.004701854796942802,\n",
       " 0.018848639526114538,\n",
       " -0.03219417948151952,\n",
       " 0.00891420084659044,\n",
       " -0.005031628679560654,\n",
       " 0.0394285928672954,\n",
       " -0.011428727167212865,\n",
       " -0.0013409947665389036,\n",
       " -0.012170718403103032,\n",
       " 0.045632464266874395,\n",
       " -0.025454423194380012,\n",
       " -0.013180651151450853,\n",
       " -0.025454423194380012,\n",
       " -0.03658429266405512,\n",
       " 0.02937048944745091,\n",
       " -0.010532154074599603,\n",
       " 0.008053696947011496,\n",
       " 0.002037899627551502,\n",
       " 0.004560154994443949,\n",
       " 0.008069155039551544,\n",
       " 0.008996644317244904,\n",
       " 0.01789023406334108,\n",
       " 0.010810401602965692,\n",
       " 0.016076477708942893,\n",
       " -0.028958271162855993,\n",
       " -0.031122413431688898,\n",
       " 0.005461880629350127,\n",
       " 0.009687109198883308,\n",
       " 0.021476526433794125,\n",
       " -0.02135286169347373,\n",
       " 0.0003333164009633885,\n",
       " 0.038253774108961254,\n",
       " 0.00876992500577578,\n",
       " 0.018848639526114538,\n",
       " 0.004709583843212827,\n",
       " 0.04212861629839841,\n",
       " 0.010068409435752924,\n",
       " 0.00561646202041192,\n",
       " 0.013170346066865022,\n",
       " -0.006064748566718551,\n",
       " -0.017900540079249513,\n",
       " 0.007131361142933654,\n",
       " 0.00932126612323114,\n",
       " 0.04963097492192235,\n",
       " 0.025289536253071086,\n",
       " -0.06628455413147868,\n",
       " -0.010851622872631623,\n",
       " 0.0046245638685812555,\n",
       " -0.006245093600567526,\n",
       " 0.025804809108814733,\n",
       " 0.004415878687967989,\n",
       " -0.0009287772968512633,\n",
       " -0.015612734001418814,\n",
       " -0.015437541044201454,\n",
       " -0.003418827993844408,\n",
       " 0.027412456320915463,\n",
       " 0.011315367511478302,\n",
       " -0.019755518634636232,\n",
       " -0.01624136465025182,\n",
       " 0.020497510801849,\n",
       " -0.01868375258480561,\n",
       " 0.01784901372499775,\n",
       " 0.025928473849135127,\n",
       " -0.016468085824366145,\n",
       " -0.01044971060394514,\n",
       " -0.03394610160311231,\n",
       " -0.017457407472219702,\n",
       " -0.012222245688677396,\n",
       " -0.021765078115423442,\n",
       " -0.015252043933720864,\n",
       " -0.009656192082480608,\n",
       " 0.02945293198678277,\n",
       " 0.03268883844280109,\n",
       " -0.014881047850114478,\n",
       " 0.030648362776933787,\n",
       " -0.009676803182974874,\n",
       " -0.003650700313267748,\n",
       " 0.04377748571148767,\n",
       " 0.001158717354707097,\n",
       " 0.0025029325183867357,\n",
       " -0.005709211041313516,\n",
       " -0.019013526467423464,\n",
       " 0.025165871512750692,\n",
       " 0.02918499233697032,\n",
       " -0.014674939639139623,\n",
       " -0.0026613786654141915,\n",
       " 0.01602495135469113,\n",
       " -0.020116208702334184,\n",
       " 0.02254829062097954,\n",
       " 0.01341767647882841,\n",
       " 0.02075514629839822,\n",
       " -0.005394895251235713,\n",
       " 0.04637445643408716,\n",
       " 0.01049608581288789,\n",
       " 0.04225228476400921,\n",
       " -0.013902031286846755,\n",
       " -0.027247569379606536,\n",
       " -0.00408352876703433,\n",
       " 0.027474288691075658,\n",
       " -0.03186440559890167,\n",
       " 0.02761856546321292,\n",
       " 0.031184245801849097,\n",
       " -0.036440015891917865,\n",
       " 0.013871115101766657,\n",
       " -0.03254456167066384,\n",
       " 0.018621920214645413,\n",
       " -0.010810401602965692,\n",
       " -0.030153701953007008,\n",
       " -0.024320826637034398,\n",
       " -0.022239128770178557,\n",
       " -0.015973423137794162,\n",
       " 0.037243840429290825,\n",
       " -0.005915319717949673,\n",
       " 0.010243602392970284,\n",
       " 0.0356361950798353,\n",
       " 0.019085664853492095,\n",
       " -0.041448460226636244,\n",
       " 0.01713793774286508,\n",
       " -0.030050647381858277,\n",
       " -0.016035257370599562,\n",
       " 0.018240619977775797,\n",
       " -0.02836055763042569,\n",
       " 0.03582169219031589,\n",
       " 0.03670795740437552,\n",
       " -0.02236279351049895,\n",
       " 0.002094579688249433,\n",
       " -0.0493012010393045,\n",
       " -0.018477645305153355,\n",
       " 0.0014182854620698002,\n",
       " 0.009187295367002314,\n",
       " 0.013087902596210559,\n",
       " 0.015829148228302104,\n",
       " -0.004173701283958817,\n",
       " 0.016643276918938302,\n",
       " -0.001684938606123576,\n",
       " -0.0002214058249891314,\n",
       " 0.006734601882201388,\n",
       " 0.009949897703386747,\n",
       " -0.015087156992411938,\n",
       " 0.060101294763716555,\n",
       " -0.021682635576091583,\n",
       " -0.05107373519271416,\n",
       " -0.004766263671080107,\n",
       " 0.006054443016471418,\n",
       " -0.027412456320915463,\n",
       " -0.010011730073546943,\n",
       " -0.06393491661481039,\n",
       " -0.014046308058984016,\n",
       " 0.010052951343212874,\n",
       " 0.007559036588746018,\n",
       " -0.011995526377208273,\n",
       " -0.007826977635542373,\n",
       " 0.03672856943619238,\n",
       " -0.0010962406257219726,\n",
       " -0.0257635869078262,\n",
       " 0.005930777810489723,\n",
       " 0.005941083360736856,\n",
       " -0.003686769273471413,\n",
       " 0.010125089729281505,\n",
       " 0.005621614562704836,\n",
       " -0.0059719995458169545,\n",
       " -0.002712905718157906,\n",
       " 0.0037408728301922354,\n",
       " 0.02078606248347832,\n",
       " 0.026876573296000152,\n",
       " -0.040335473838462296,\n",
       " -0.004928574108411925,\n",
       " 0.001768670212351268,\n",
       " 0.0002784077740612133,\n",
       " -0.009955049780018361,\n",
       " -0.008584426963972588,\n",
       " 0.02182691048558364,\n",
       " -0.012953931839981732,\n",
       " 0.021167362720347936,\n",
       " 0.016478389977629376,\n",
       " 0.017220382144842145,\n",
       " -0.00629662088614189,\n",
       " 0.01039303124173916,\n",
       " 0.0024436761865423468,\n",
       " -0.0049904069442334225,\n",
       " -0.012552019571295248,\n",
       " -0.02471243288981245,\n",
       " -0.005992610180649919,\n",
       " 0.005062544864640753,\n",
       " 0.04839432379342801,\n",
       " 0.0034780843256887973,\n",
       " 0.02543381302520835,\n",
       " -0.03050408786744173,\n",
       " 0.022919286704585925,\n",
       " -0.01241804881506642,\n",
       " -0.020487204785940568,\n",
       " -0.018539477675313554,\n",
       " -0.025825419277986397,\n",
       " 0.03260639404082403,\n",
       " -0.02411471749473694,\n",
       " 0.028999493363844525,\n",
       " -0.018158175575798734,\n",
       " -0.011892471806059544,\n",
       " 0.007553883580791801,\n",
       " 0.03501786765294293,\n",
       " -0.006997390386704826,\n",
       " 0.0004605241252906194,\n",
       " -0.012799349983258638,\n",
       " -0.002805654739059502,\n",
       " 0.03394610160311231,\n",
       " 0.0008965728597826107,\n",
       " 0.031967458307405196,\n",
       " -0.0028984035271304477,\n",
       " 0.015623039086004646,\n",
       " -0.03141096697596342,\n",
       " 0.028030783747807837,\n",
       " -0.02028109564364311,\n",
       " -0.002081697866855842,\n",
       " -0.0021023087345194576,\n",
       " 0.0035965967565469254,\n",
       " 0.0033544191197071027,\n",
       " 0.015447847060109888,\n",
       " 0.005503102364677359,\n",
       " 0.0017995865138466917,\n",
       " -0.012253161873757495,\n",
       " -0.033781216524448585,\n",
       " 0.009547985434700264,\n",
       " 0.0034497444117551567,\n",
       " -0.03691406654667297,\n",
       " -0.005358826058201397,\n",
       " 0.005771043411473713,\n",
       " -0.003722838233675078,\n",
       " -0.014087529328649947,\n",
       " -0.0007922303276836402,\n",
       " 0.017941762280238045,\n",
       " -0.019219635609720922,\n",
       " 0.021146752551176273,\n",
       " -0.0008051120908695688,\n",
       " 0.004799756360137315,\n",
       " -0.009367640400851288,\n",
       " -0.03584230422213276,\n",
       " 0.03314227706573934,\n",
       " -0.01807573303646687,\n",
       " 0.01677724767516713,\n",
       " 0.015118073177492036,\n",
       " 0.008373165745043515,\n",
       " -0.0028185363276224426,\n",
       " 0.024609378318663718,\n",
       " 0.0021113260327780365,\n",
       " 0.011335978611972568,\n",
       " -0.003555375021219694,\n",
       " -0.010150852906407387,\n",
       " 0.021662023544274715,\n",
       " -0.006523340197611013,\n",
       " -0.005781348961720846,\n",
       " -0.0037717892481029846,\n",
       " -0.005734974684100698,\n",
       " -0.04658056557638462,\n",
       " 0.01645777980845771,\n",
       " 0.002442388167384443,\n",
       " 0.033410218578196996,\n",
       " 0.03281250318312149,\n",
       " 0.009790162838709437,\n",
       " 0.0044313367805080385,\n",
       " -8.272526668201199e-06,\n",
       " 0.0016900912648318174,\n",
       " 0.018900167743011502,\n",
       " -0.007002542928997742,\n",
       " 0.0005323400991161359,\n",
       " -0.03338961027167053,\n",
       " 0.04142784819481938,\n",
       " -0.005709211041313516,\n",
       " 0.010738263216897062,\n",
       " -0.011943999091633909,\n",
       " -0.019559715508247207,\n",
       " -0.013108512765382224,\n",
       " -0.00958405462773458,\n",
       " -0.028216280858288426,\n",
       " 0.01624136465025182,\n",
       " -0.051609618217629466,\n",
       " 0.021146752551176273,\n",
       " 0.005838028789588127,\n",
       " -0.02568114436849434,\n",
       " -0.01576731585814191,\n",
       " -0.01191308290655381,\n",
       " -0.0019155226735583617,\n",
       " -0.009635581913308943,\n",
       " -0.0075075093031716535,\n",
       " 0.01166575249459042,\n",
       " -0.02339333735934104,\n",
       " -0.015355097573546991,\n",
       " 0.010001424988961111,\n",
       " -0.0027438221360686545,\n",
       " -0.006580020025478294,\n",
       " 0.006739754424494304,\n",
       " -0.012789044898672806,\n",
       " 0.013366149193254045,\n",
       " -0.01191308290655381,\n",
       " -2.0630998419926373e-05,\n",
       " 0.0005635784636086981,\n",
       " -0.02343455956032957,\n",
       " 0.03839805088109852,\n",
       " 0.02611397282226092,\n",
       " -0.0019928133690892583,\n",
       " 0.019755518634636232,\n",
       " -0.0012669243517334171,\n",
       " 0.0008186379800497744,\n",
       " -0.002844299970409625,\n",
       " -0.0029937288191785017,\n",
       " 0.004508627708869585,\n",
       " 0.0019142345379851325,\n",
       " -0.027350623950755264,\n",
       " -0.0029550833549977285,\n",
       " -0.0040861048053501365,\n",
       " -0.01681846987615566,\n",
       " -0.030772029379899382,\n",
       " -0.007811519543002323,\n",
       " -0.017045189187624783,\n",
       " -0.0013976745944061844,\n",
       " 0.021476526433794125,\n",
       " 0.03784155582436634,\n",
       " -0.014303943555533239,\n",
       " -0.007414760282270057,\n",
       " -0.001429879031474837,\n",
       " 0.010532154074599603,\n",
       " 0.020095598533162517,\n",
       " 0.01284057218424717,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PineCone Document Link](https://python.langchain.com/docs/integrations/vectorstores/pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import Pinecone\n",
    "\n",
    "index_name = \"intro-to-langchain\"\n",
    "\n",
    "docsearch = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is magical about Autoencoder?\"\n",
    "result = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Autoencoder is like a magic machine that can shrink big things into small things and then make them'), Document(page_content='An autoencoder is like a magic box that can take a big picture and turn it into a small picture,'), Document(page_content='In simpler terms, an autoencoder is like a magic toy box because it can take in a large amount of'), Document(page_content='kind of like what an autoencoder does with data.')]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Document(page_content='Autoencoder is like a magic machine that can shrink big things into small things and then make them'), Document(page_content='An autoencoder is like a magic box that can take a big picture and turn it into a small picture,'), Document(page_content='In simpler terms, an autoencoder is like a magic toy box because it can take in a large amount of'), Document(page_content='kind of like what an autoencoder does with data.')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_experimental.tools import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [PythonREPLTool()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "If you get an error, debug your code and try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(ChatOpenAI(temperature=0), tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "fibonacci(10)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe 10th place in the Fibonacci series is 55.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 10th place fibonacci series?',\n",
       " 'output': 'The 10th place in the Fibonacci series is 55.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the 10th place fibonacci series?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fibonacci Example](https://python.langchain.com/docs/integrations/toolkits/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
